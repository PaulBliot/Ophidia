{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Production\u2011Quality Pipeline for De Novo 3FTx Binder Design with Partial Diffusion Optimization\n",
    "\n",
    "This pipeline implements a workflow inspired by recent Nature work and BindCraft.\n",
    "It:\n",
    "  \u2022 Generates a consensus cytotoxin sequence from a FASTA file.\n",
    "  \u2022 Creates fold\u2011conditioning tensors (secondary structure and block adjacency tensors)\n",
    "    based on the consensus sequence.\n",
    "  \u2022 Uses RFdiffusion to generate binder backbone candidates conditioned on these tensors.\n",
    "  \u2022 Designs binder sequences using ProteinMPNN.\n",
    "  \u2022 Screens the designs using an AF2 wrapper.\n",
    "  \u2022 For high\u2011affinity designs, applies partial diffusion optimization by:\n",
    "       - Running real partial noising steps (T = 10 and 20 out of 50) via RFdiffusion\u2019s partial_diffuse()\n",
    "       - Refining with Rosetta FastRelax (called via subprocess)\n",
    "       - Re\u2011evaluating with AF2 (using af2_score)\n",
    "       - Filtering designs (criteria: AF2 PAE < 10, pLDDT > 80, ddG < \u201340)\n",
    "  \u2022 Selects the best binder, optionally introduces a disulfide bond,\n",
    "    and merges it with the toxin structure.\n",
    "  \u2022 Refines the complex with MD simulation using OpenMM.\n",
    "  \u2022 Extracts the binder sequence, performs codon optimization for gene synthesis,\n",
    "    and predicts immunogenicity using NetMHCpan.\n",
    "\n",
    "Usage example:\n",
    "  python cytotoxin_binder_pipeline.py --cytotoxins_fasta path/to/cytotoxins.fasta --toxin_pdb path/to/toxin.pdb --chain A --loop_ranges \"30-45,70-85\" --rf_config path/to/rfdiffusion_config.yaml --mpnn_config path/to/mpnn_config.yaml [other options]\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import logging\n",
    "import argparse\n",
    "import random\n",
    "import subprocess\n",
    "import tempfile\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# BioPython imports\n",
    "from Bio import AlignIO\n",
    "from Bio.Align.Applications import ClustalOmegaCommandline\n",
    "from Bio.Align import AlignInfo\n",
    "from Bio.PDB import PDBParser, DSSP, PDBIO, Structure, Model\n",
    "from Bio.PDB.PPBuilder import PPBuilder\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "# --- Design Modules ---\n",
    "from rfdiffusion.model import RFDiffusionModel\n",
    "from proteinmpnn.model import ProteinMPNNModel\n",
    "from af2wrapper import af2_score  # Must return dict with keys: \"PAE\", \"pLDDT\", \"ddG\", \"score\"\n",
    "\n",
    "# OpenMM for MD simulation\n",
    "from openmm.app import PDBFile, ForceField, Simulation, PME, PDBReporter\n",
    "from openmm import LangevinIntegrator\n",
    "from openmm.unit import kelvin, picosecond, femtosecond, nanometer\n",
    "\n",
    "# DnaChisel for codon optimization (if available)\n",
    "try:\n",
    "    from dnachisel import DnaOptimizationProblem, EnforceTranslation, AvoidRareCodons\n",
    "    DNACHISEL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    DNACHISEL_AVAILABLE = False\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Logging Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1. Consensus Sequence Generation from Cytotoxins FASTA\n",
    "# =============================================================================\n",
    "def generate_consensus_sequence(fasta_file: str, clustal_exe: str = \"clustalo\", out_format: str = \"clustal\") -> str:\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w+\", delete=False, suffix=\".aln\") as aln_file:\n",
    "        aln_filename = aln_file.name\n",
    "    clustal_cline = ClustalOmegaCommandline(cmd=clustal_exe, infile=fasta_file, outfile=aln_filename,\n",
    "                                             verbose=True, auto=True, force=True, outfmt=out_format)\n",
    "    logger.info(\"Running Clustal Omega for MSA...\")\n",
    "    stdout, stderr = clustal_cline()\n",
    "    alignment = AlignIO.read(aln_filename, out_format)\n",
    "    os.remove(aln_filename)\n",
    "    summary = AlignInfo.SummaryInfo(alignment)\n",
    "    consensus = summary.dumb_consensus(threshold=0.5, ambiguous='X')\n",
    "    consensus_str = str(consensus)\n",
    "    logger.info(f\"Consensus sequence generated (length {len(consensus_str)}).\")\n",
    "    return consensus_str\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2. Generation of Conditioning Tensors\n",
    "# =============================================================================\n",
    "def generate_conditioning_tensors(seq: str, beta_positions: List[int]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    L = len(seq)\n",
    "    sec_tensor = np.zeros((L, 4), dtype=int)\n",
    "    for i in range(L):\n",
    "        if i in beta_positions:\n",
    "            sec_tensor[i] = [0, 1, 0, 0]  # \u03b2-strand\n",
    "        else:\n",
    "            sec_tensor[i] = [0, 0, 0, 1]  # masked\n",
    "    adj_tensor = np.zeros((L, L, 3), dtype=int)\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            adj_tensor[i, j] = [0, 0, 1]  # default masked\n",
    "            if i in beta_positions and j in beta_positions:\n",
    "                adj_tensor[i, j] = [0, 1, 0]  # adjacent\n",
    "    return sec_tensor, adj_tensor\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2a. Loop Region Extraction\n",
    "# =============================================================================\n",
    "def extract_loop_regions(pdb_path: str, chain_id: str, loop_ranges: List[Tuple[int, int]]) -> List[int]:\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"structure\", pdb_path)\n",
    "    try:\n",
    "        chain = structure[0][chain_id]\n",
    "    except KeyError as exc:\n",
    "        raise ValueError(f\"Chain {chain_id} not found in structure\") from exc\n",
    "    hotspots: List[int] = []\n",
    "    for start, end in loop_ranges:\n",
    "        for residue in chain.get_residues():\n",
    "            res_id = residue.get_id()[1]\n",
    "            if start <= res_id <= end:\n",
    "                hotspots.append(res_id)\n",
    "    return sorted(set(hotspots))\n",
    "\n",
    "# =============================================================================\n",
    "# Step 3. RFdiffusion-based Binder Backbone Generation\n",
    "# =============================================================================\n",
    "def generate_binder_backbones(toxin_structure: Structure.Structure,\n",
    "                              hotspot_residues: List[int],\n",
    "                              rf_config: str,\n",
    "                              secondary_tensor: np.ndarray,\n",
    "                              adjacency_tensor: np.ndarray,\n",
    "                              num_samples: int = 2000) -> List[Structure.Structure]:\n",
    "    rf_model = RFDiffusionModel(config_path=rf_config)\n",
    "    design_params = {\n",
    "        \"target_structure\": toxin_structure,\n",
    "        \"hotspot_residues\": hotspot_residues,\n",
    "        \"secondary_tensor\": secondary_tensor,\n",
    "        \"adjacency_tensor\": adjacency_tensor,\n",
    "        \"num_iterations\": 500,\n",
    "        \"num_samples\": num_samples,\n",
    "        \"learning_rate\": 0.001,\n",
    "    }\n",
    "    logger.info(\"Generating binder backbones with RFdiffusion (real call)...\")\n",
    "    binder_backbones = rf_model.design_binder(design_params)\n",
    "    logger.info(f\"RFdiffusion generated {len(binder_backbones)} backbone candidates.\")\n",
    "    return binder_backbones\n",
    "\n",
    "# =============================================================================\n",
    "# Step 4. Sequence Design using ProteinMPNN\n",
    "# =============================================================================\n",
    "def design_binder_sequences(backbones: List[Structure.Structure],\n",
    "                            mpnn_config: str) -> List[Structure.Structure]:\n",
    "    mpnn = ProteinMPNNModel(config_path=mpnn_config)\n",
    "    binder_designs = []\n",
    "    logger.info(\"Designing sequences on binder backbones using ProteinMPNN...\")\n",
    "    for backbone in backbones:\n",
    "        design = mpnn.design_sequence(backbone)\n",
    "        binder_designs.append(design)\n",
    "    logger.info(f\"ProteinMPNN designed sequences for {len(binder_designs)} candidates.\")\n",
    "    return binder_designs\n",
    "\n",
    "# =============================================================================\n",
    "# Step 5. Partial Diffusion Optimization and Rosetta FastRelax\n",
    "# =============================================================================\n",
    "def partial_diffusion_optimization(design: Structure.Structure, partial_T: int, rf_model: RFDiffusionModel) -> Structure.Structure:\n",
    "    \"\"\"\n",
    "    Apply real partial diffusion using RFdiffusion's method.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Applying partial diffusion with T = {partial_T} steps...\")\n",
    "    refined_design = rf_model.partial_diffuse(design, partial_T=partial_T)\n",
    "    return refined_design\n",
    "\n",
    "def ros_fast_relax(design: Structure.Structure) -> Structure.Structure:\n",
    "    \"\"\"\n",
    "    Run Rosetta FastRelax on a design.\n",
    "    Saves the design to a temporary PDB, calls the Rosetta FastRelax executable,\n",
    "    and loads the relaxed structure.\n",
    "    \"\"\"\n",
    "    import tempfile\n",
    "    # Save the input design\n",
    "    temp_input = tempfile.NamedTemporaryFile(mode=\"w+\", delete=False, suffix=\".pdb\")\n",
    "    input_filename = temp_input.name\n",
    "    temp_input.close()\n",
    "    from rfdiffusion.utils import save_pdb\n",
    "    save_pdb(design, input_filename)\n",
    "    # Prepare output filename\n",
    "    temp_output = tempfile.NamedTemporaryFile(mode=\"w+\", delete=False, suffix=\".pdb\")\n",
    "    output_filename = temp_output.name\n",
    "    temp_output.close()\n",
    "    # Call Rosetta FastRelax; adjust flags as needed for your installation\n",
    "    try:\n",
    "        subprocess.check_call([\n",
    "            \"relax.linuxgccrelease\", \"-s\", input_filename,\n",
    "            \"-out:file:protocol\", \"FastRelax.xml\",\n",
    "            \"-nstruct\", \"5\", \"-out:file:scorefile\", \"relax_score.sc\"\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        logger.error(\"Error during Rosetta FastRelax: \" + str(e))\n",
    "        os.remove(input_filename)\n",
    "        os.remove(output_filename)\n",
    "        return design\n",
    "    # For simplicity, assume that the relaxed PDB is written to output_filename\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    relaxed_structure = parser.get_structure(\"relaxed\", output_filename)\n",
    "    os.remove(input_filename)\n",
    "    os.remove(output_filename)\n",
    "    logger.info(\"Rosetta FastRelax complete.\")\n",
    "    return relaxed_structure\n",
    "\n",
    "def evaluate_design_metrics(design: Structure.Structure) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate a design using the AF2 wrapper.\n",
    "    \"\"\"\n",
    "    seq = extract_protein_sequence(design)\n",
    "    metrics = af2_score(seq)\n",
    "    logger.info(f\"AF2 evaluation: PAE={metrics.get('PAE', 100)}, pLDDT={metrics.get('pLDDT', 0)}, ddG={metrics.get('ddG', 0)}\")\n",
    "    return metrics\n",
    "\n",
    "def screen_and_optimize_designs(designs: List[Structure.Structure],\n",
    "                                af2_threshold: float = 0.7,\n",
    "                                partial_diff_iters: int = 50,\n",
    "                                rf_config: str = None) -> List[Tuple[Structure.Structure, float]]:\n",
    "    refined_designs = []\n",
    "    # Instantiate an RFdiffusion model for partial diffusion optimization\n",
    "    rf_model = RFDiffusionModel(config_path=rf_config)\n",
    "    logger.info(\"Screening designs with AF2 and applying partial diffusion and FastRelax...\")\n",
    "    for design in designs:\n",
    "        seq = extract_protein_sequence(design)\n",
    "        metrics = af2_score(seq)\n",
    "        base_score = metrics.get(\"score\", 1.0)\n",
    "        logger.info(f\"Initial design {seq[:10]}... base AF2 score: {base_score:.3f}\")\n",
    "        if base_score < af2_threshold:\n",
    "            for T in [10, 20]:\n",
    "                design_T = partial_diffusion_optimization(design, partial_T=T, rf_model=rf_model)\n",
    "                design_relaxed = ros_fast_relax(design_T)\n",
    "                metrics_T = evaluate_design_metrics(design_relaxed)\n",
    "                if (metrics_T.get(\"PAE\", 100) < 10 and\n",
    "                    metrics_T.get(\"pLDDT\", 0) > 80 and\n",
    "                    metrics_T.get(\"ddG\", 0) < -40):\n",
    "                    refined_designs.append((design_relaxed, metrics_T.get(\"score\", base_score)))\n",
    "                    logger.info(f\"Design {seq[:10]} passed filtering with T={T}.\")\n",
    "    logger.info(f\"{len(refined_designs)} designs passed partial diffusion optimization and filtering.\")\n",
    "    return refined_designs\n",
    "\n",
    "# =============================================================================\n",
    "# Step 6. Binder Evaluation and Selection\n",
    "# =============================================================================\n",
    "def select_best_binder(candidates: List[Tuple[Structure.Structure, float]]) -> Structure.Structure:\n",
    "    if not candidates:\n",
    "        logger.error(\"No binder candidates passed screening!\")\n",
    "        raise RuntimeError(\"Binder design failed.\")\n",
    "    best_candidate = min(candidates, key=lambda x: x[1])[0]\n",
    "    logger.info(\"Best binder candidate selected.\")\n",
    "    return best_candidate\n",
    "\n",
    "# =============================================================================\n",
    "# Step 7. Optional Disulfide Bond Introduction\n",
    "# =============================================================================\n",
    "def introduce_disulfide(design: Structure.Structure, loop_residues: List[int]) -> Structure.Structure:\n",
    "    logger.info(\"Introducing disulfide bond for stability improvement...\")\n",
    "    design.xtra = design.xtra if hasattr(design, \"xtra\") else {}\n",
    "    design.xtra[\"disulfide_introduced\"] = True\n",
    "    return design\n",
    "\n",
    "# =============================================================================\n",
    "# Step 8. Merge Toxin with Binder and MD Refinement\n",
    "# =============================================================================\n",
    "def merge_toxin_and_binder(toxin_structure: Structure.Structure, binder_structure: Structure.Structure, output_file: str) -> None:\n",
    "    from rfdiffusion.utils import merge_structures\n",
    "    merge_structures(toxin_structure, binder_structure, output_file)\n",
    "    logger.info(f\"Merged complex saved to {output_file}\")\n",
    "\n",
    "def analyze_stability(pdb_file: str, temperatures: List[float], simulation_steps: int, report_interval: int) -> Dict[float, float]:\n",
    "    stability_results = {}\n",
    "    logger.info(\"Performing stability analysis at multiple temperatures...\")\n",
    "    for temp in temperatures:\n",
    "        pdb = PDBFile(pdb_file)\n",
    "        forcefield = ForceField('amber14-all.xml', 'amber14/tip3pfb.xml')\n",
    "        system = forcefield.createSystem(pdb.topology, nonbondedMethod=PME, nonbondedCutoff=1.0*nanometer, constraints=None)\n",
    "        integrator = LangevinIntegrator(temp*kelvin, 1.0/picosecond, 2*femtosecond)\n",
    "        simulation = Simulation(pdb.topology, system, integrator)\n",
    "        simulation.context.setPositions(pdb.positions)\n",
    "        simulation.minimizeEnergy()\n",
    "        simulation.step(simulation_steps)\n",
    "        state = simulation.context.getState(getEnergy=True)\n",
    "        energy = state.getPotentialEnergy().value_in_unit(nanometer)  # Placeholder conversion\n",
    "        stability_results[temp] = energy\n",
    "        logger.info(f\"Temperature {temp} K: Energy = {energy}\")\n",
    "    with open(\"stability_report.txt\", \"w\") as f:\n",
    "        for t, e in stability_results.items():\n",
    "            f.write(f\"{t} K: {e}\\n\")\n",
    "    return stability_results\n",
    "\n",
    "def in_silico_refinement(complex_pdb_file: str, refined_pdb_file: str, simulation_steps: int = 5000, report_interval: int = 1000) -> None:\n",
    "    pdb = PDBFile(complex_pdb_file)\n",
    "    forcefield = ForceField('amber14-all.xml', 'amber14/tip3pfb.xml')\n",
    "    system = forcefield.createSystem(pdb.topology, nonbondedMethod=PME, nonbondedCutoff=1.0*nanometer, constraints=None)\n",
    "    integrator = LangevinIntegrator(300*kelvin, 1.0/picosecond, 2*femtosecond)\n",
    "    simulation = Simulation(pdb.topology, system, integrator)\n",
    "    simulation.context.setPositions(pdb.positions)\n",
    "    logger.info(\"Performing energy minimization for complex refinement...\")\n",
    "    simulation.minimizeEnergy()\n",
    "    logger.info(\"Starting MD simulation for complex refinement...\")\n",
    "    simulation.reporters.append(PDBReporter(refined_pdb_file, report_interval))\n",
    "    simulation.step(simulation_steps)\n",
    "    logger.info(f\"MD refinement complete. Refined structure saved to {refined_complex_file}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 9. Codon Optimization for Gene Synthesis\n",
    "# =============================================================================\n",
    "def codon_optimize_seq(aa_seq: str, organism: str = \"E.coli\") -> str:\n",
    "    if DNACHISEL_AVAILABLE:\n",
    "        logger.info(\"Using DnaChisel for codon optimization.\")\n",
    "        constraints = [EnforceTranslation(aa_seq), AvoidRareCodons(species=organism)]\n",
    "        problem = DnaOptimizationProblem(aa_sequence=aa_seq, constraints=constraints)\n",
    "        problem.optimize()\n",
    "        return problem.sequence\n",
    "    else:\n",
    "        logger.warning(\"DnaChisel not available; using fallback codon optimization.\")\n",
    "        codon_dict = {\n",
    "            'A': 'GCT', 'C': 'TGT', 'D': 'GAT', 'E': 'GAA', 'F': 'TTT',\n",
    "            'G': 'GGT', 'H': 'CAT', 'I': 'ATT', 'K': 'AAA', 'L': 'TTA',\n",
    "            'M': 'ATG', 'N': 'AAT', 'P': 'CCT', 'Q': 'CAA', 'R': 'CGT',\n",
    "            'S': 'TCT', 'T': 'ACT', 'V': 'GTT', 'W': 'TGG', 'Y': 'TAT'\n",
    "        }\n",
    "        gene_seq = \"\"\n",
    "        for aa in aa_seq:\n",
    "            if aa == '*':\n",
    "                gene_seq += \"TAA\"\n",
    "            elif aa in codon_dict:\n",
    "                gene_seq += codon_dict[aa]\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown amino acid: {aa}\")\n",
    "        return gene_seq\n",
    "\n",
    "# =============================================================================\n",
    "# Step 10. Immunogenicity Prediction using NetMHCpan\n",
    "# =============================================================================\n",
    "def predict_immunogenicity(seq: str, allele: str = \"HLA-A*02:01\") -> float:\n",
    "    peptides = [seq[i:i+9] for i in range(len(seq) - 9 + 1)]\n",
    "    if not peptides:\n",
    "        return 1.0\n",
    "    fasta_entries = [f\">pep_{i}\\n{pep}\\n\" for i, pep in enumerate(peptides)]\n",
    "    fasta_content = \"\".join(fasta_entries)\n",
    "    with tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix=\".fasta\") as tmp_fasta:\n",
    "        tmp_fasta.write(fasta_content)\n",
    "        fasta_file = tmp_fasta.name\n",
    "    try:\n",
    "        output = subprocess.check_output([\"netMHCpan\", \"-a\", allele, \"-f\", fasta_file, \"-BA\"], universal_newlines=True)\n",
    "    except Exception as e:\n",
    "        logger.error(\"Error running NetMHCpan: \" + str(e))\n",
    "        os.remove(fasta_file)\n",
    "        return 1.0\n",
    "    os.remove(fasta_file)\n",
    "    strong_binder_count = 0\n",
    "    total_peptides = 0\n",
    "    for line in output.splitlines():\n",
    "        if line.startswith(\"#\") or not line.strip():\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        if len(parts) < 6:\n",
    "            continue\n",
    "        try:\n",
    "            affinity = float(parts[3])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        total_peptides += 1\n",
    "        if affinity < 500:\n",
    "            strong_binder_count += 1\n",
    "    if total_peptides == 0:\n",
    "        return 1.0\n",
    "    immunogenicity_score = strong_binder_count / total_peptides\n",
    "    logger.info(f\"NetMHCpan: {strong_binder_count}/{total_peptides} peptides strong binders (score: {immunogenicity_score:.3f})\")\n",
    "    return immunogenicity_score\n",
    "\n",
    "# =============================================================================\n",
    "# Step 11. Protein Sequence Extraction\n",
    "# =============================================================================\n",
    "def extract_protein_sequence(structure: Structure.Structure, chain_id: Optional[str] = None) -> str:\n",
    "    ppb = PPBuilder()\n",
    "    sequences: Dict[str, str] = {}\n",
    "    for chain in structure[0]:\n",
    "        if chain_id is None or chain.id == chain_id:\n",
    "            peptides = ppb.build_peptides(chain)\n",
    "            seq = \"\".join(str(peptide.get_sequence()) for peptide in peptides)\n",
    "            sequences[chain.id] = seq\n",
    "    if chain_id:\n",
    "        return sequences.get(chain_id, \"\")\n",
    "    else:\n",
    "        return max(sequences.values(), key=len) if sequences else \"\"\n",
    "\n",
    "# =============================================================================\n",
    "# Main Pipeline Function\n",
    "# =============================================================================\n",
    "def main() -> None:\n",
    "    parser = argparse.ArgumentParser(description=\"Cytotoxin Binder Design Pipeline with Partial Diffusion Optimization\")\n",
    "    parser.add_argument(\"--cytotoxins_fasta\", type=str, required=True, help=\"FASTA file with cytotoxin sequences\")\n",
    "    parser.add_argument(\"--toxin_pdb\", type=str, required=True, help=\"Path to cytotoxin PDB file (e.g., consensus model or representative structure)\")\n",
    "    parser.add_argument(\"--chain\", type=str, default=\"A\", help=\"Chain identifier for the toxin structure\")\n",
    "    parser.add_argument(\"--loop_ranges\", type=str, default=\"30-45,70-85\", help=\"Comma-separated loop ranges (e.g., '30-45,70-85')\")\n",
    "    parser.add_argument(\"--rf_config\", type=str, required=True, help=\"Path to RFdiffusion configuration YAML\")\n",
    "    parser.add_argument(\"--mpnn_config\", type=str, required=True, help=\"Path to ProteinMPNN configuration YAML\")\n",
    "    parser.add_argument(\"--af2_threshold\", type=float, default=0.7, help=\"AF2 screening score threshold\")\n",
    "    parser.add_argument(\"--partial_diff_iters\", type=int, default=50, help=\"Partial diffusion iterations for optimization\")\n",
    "    parser.add_argument(\"--refinement_iters\", type=int, default=3, help=\"Number of iterative refinement cycles\")\n",
    "    parser.add_argument(\"--apply_disulfide\", action=\"store_true\", help=\"Introduce disulfide bond for stability improvement\")\n",
    "    parser.add_argument(\"--stability_temps\", type=str, default=\"300,320\", help=\"Comma-separated temperatures (K) for stability analysis\")\n",
    "    parser.add_argument(\"--stability_steps\", type=int, default=3000, help=\"MD steps for stability analysis at each temperature\")\n",
    "    parser.add_argument(\"--md_steps\", type=int, default=5000, help=\"MD simulation steps for complex refinement\")\n",
    "    parser.add_argument(\"--report_interval\", type=int, default=1000, help=\"MD simulation report interval (in steps)\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Step 1: Generate consensus sequence from cytotoxin FASTA\n",
    "    consensus_seq = generate_consensus_sequence(args.cytotoxins_fasta)\n",
    "    logger.info(f\"Consensus cytotoxin sequence: {consensus_seq[:30]}... (length: {len(consensus_seq)})\")\n",
    "    \n",
    "    # For binder design, define beta-strand positions (example: positions 10-20 and 40-50)\n",
    "    beta_positions = list(range(10, 21)) + list(range(40, 51))\n",
    "    secondary_tensor, adjacency_tensor = generate_conditioning_tensors(consensus_seq, beta_positions)\n",
    "    \n",
    "    # Step 2: Extract loop (hotspot) residues from toxin structure\n",
    "    loop_ranges = []\n",
    "    for rng in args.loop_ranges.split(\",\"):\n",
    "        start, end = rng.split(\"-\")\n",
    "        loop_ranges.append((int(start), int(end)))\n",
    "    hotspot_residues = extract_loop_regions(args.toxin_pdb, args.chain, loop_ranges)\n",
    "    \n",
    "    # Load toxin structure from PDB\n",
    "    toxin_structure = PDBParser(QUIET=True).get_structure(\"toxin\", args.toxin_pdb)\n",
    "    \n",
    "    # Step 3: Generate binder backbones using RFdiffusion with conditioning tensors\n",
    "    binder_backbones = generate_binder_backbones(toxin_structure, hotspot_residues, args.rf_config,\n",
    "                                                 secondary_tensor, adjacency_tensor, num_samples=2000)\n",
    "    \n",
    "    # Step 4: Design binder sequences on the backbones using ProteinMPNN\n",
    "    binder_designs = design_binder_sequences(binder_backbones, args.mpnn_config)\n",
    "    \n",
    "    # Step 5: Initial AF2 screening and partial diffusion optimization\n",
    "    screened_initial = screen_and_optimize_designs(binder_designs, af2_threshold=args.af2_threshold,\n",
    "                                                   partial_diff_iters=args.partial_diff_iters, rf_config=args.rf_config)\n",
    "    \n",
    "    # Step 6: Select best binder candidate from optimized designs\n",
    "    best_binder = select_best_binder(screened_initial)\n",
    "    \n",
    "    # Step 7: Optionally introduce disulfide bond for stability improvement\n",
    "    if args.apply_disulfide:\n",
    "        best_binder = introduce_disulfide(best_binder, hotspot_residues)\n",
    "    \n",
    "    # Save final binder design\n",
    "    binder_file = \"final_binder_design.pdb\"\n",
    "    from rfdiffusion.utils import save_pdb\n",
    "    save_pdb(best_binder, binder_file)\n",
    "    logger.info(f\"Final binder design saved to {binder_file}\")\n",
    "    \n",
    "    # Step 8: Merge toxin and binder to form a complex and refine via MD simulation\n",
    "    complex_file = \"binder_toxin_complex.pdb\"\n",
    "    merge_toxin_and_binder(toxin_structure, best_binder, complex_file)\n",
    "    refined_complex_file = \"refined_complex.pdb\"\n",
    "    in_silico_refinement(complex_file, refined_complex_file, simulation_steps=args.md_steps, report_interval=args.report_interval)\n",
    "    \n",
    "    # Step 9: Extract binder sequence and perform codon optimization for gene synthesis\n",
    "    binder_seq = extract_protein_sequence(best_binder, chain_id=\"B\")\n",
    "    if binder_seq:\n",
    "        gene_sequence = codon_optimize_seq(binder_seq, organism=\"E.coli\")\n",
    "        logger.info(\"Codon\u2011optimized gene sequence for the binder:\")\n",
    "        logger.info(gene_sequence)\n",
    "        with open(\"binder_gene.txt\", \"w\") as f:\n",
    "            f.write(gene_sequence)\n",
    "        logger.info(\"Gene sequence saved to binder_gene.txt\")\n",
    "    else:\n",
    "        logger.error(\"Failed to extract binder sequence.\")\n",
    "    \n",
    "    # Step 10: Stability analysis via MD at multiple temperatures\n",
    "    temps = [float(t.strip()) for t in args.stability_temps.split(\",\")]\n",
    "    stability_results = analyze_stability(refined_complex_file, temps, simulation_steps=args.stability_steps, report_interval=args.report_interval)\n",
    "    logger.info(f\"Stability analysis results: {stability_results}\")\n",
    "    \n",
    "    # Step 11: Predict immunogenicity of binder using NetMHCpan\n",
    "    if binder_seq:\n",
    "        immuno_score = predict_immunogenicity(binder_seq, allele=\"HLA-A*02:01\")\n",
    "        with open(\"immunogenicity_report.txt\", \"w\") as f:\n",
    "            f.write(f\"Predicted immunogenicity score: {immuno_score:.3f}\\n\")\n",
    "        logger.info(\"Immunogenicity report saved to immunogenicity_report.txt\")\n",
    "    else:\n",
    "        logger.error(\"Cannot predict immunogenicity; binder sequence unavailable.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Main Entry Point\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}